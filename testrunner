#!/usr/bin/env python

from __future__ import print_function

import json
import os

from argparse import ArgumentParser, Action
from fnmatch import fnmatch
from select import select
from subprocess import Popen, PIPE


class Colors:
    GRAY = "\x1b[90m"
    RED = "\x1b[91m"
    GREEN = "\x1b[92m"
    DEFAULT = "\x1b[39m"


class TestModule:

    def __init__(self, module_path, idx):
        self.module_path = module_path
        self.idx = idx
        self.finished = False
        self.failed = False
        self.events = []
        self.tests = []

    def list(self):
        args = [os.path.abspath(self.module_path), '--list']
        self.proc = Popen(args, stdout=PIPE)

    def run(self, test_indices, valgrind):
        args = []
        if valgrind:
            log_path = "valgrind.{}.log".format(os.path.basename(self.module_path))
            print("VALGRIND MODE ENABLED")
            print()
            print("The test process will be run under Valgrind. Any errors found will be logged to:")
            print()
            print("\t{}".format(log_path))
            print()
            args.extend(['valgrind', '--quiet', "--log-file={}".format(log_path)])
        args.extend([os.path.abspath(self.module_path), '--run', *map(str, test_indices)])
        self.proc = Popen(args, stdout=PIPE)

    def read_events(self):
        # Check the status of the process
        self.proc.poll()

        # Yield all pending events
        for line in self.proc.stdout:
            try:
                event = json.loads(line.decode())
            except ValueError:
                event = {
                    'event': 'testcase_error',
                    'message': "Failed to parse test case output",
                    'crash': False
                }
            yield event

        # Handle process completion
        if self.proc.returncode is not None:
            self.finished = True
            if self.proc.returncode != 0:
                self.failed = True

    def reset_status(self):
        self.finished = False
        self.failed = False

    def fileno(self):
        return self.proc.stdout.fileno()

    def read(self, size):
        return self.proc.stdout.read(size)

    def print_debug_help(self):
        print("DEBUG MODE ENABLED")
        print()
        print("The test process will stop and wait for SIGCONT. Run the following command to")
        print("attach with gdb:")
        print()
        print("\tgdb {} {}".format(self.module_path, self.proc.pid))
        print()
        print("After attaching to the process with gdb, you can set breakpoints before")
        print("resuming the process by sending SIGCONT:")
        print()
        print("\t(gdb) signal SIGCONT")
        print()


class Runner:

    def __init__(self, module_paths):
        self.observers = []
        self.modules = [TestModule(t, i) for i, t in enumerate(module_paths)]

    def register(self, observer):
        self.observers.append(observer)

    def deregister(self, observer):
        self.observers.remove(observer)

    def list_modules(self):
        for m in self.modules:
            m.list()
        self.handle_events(self.modules)

    def run_modules(self, tests_to_run, debug=False, valgrind=False):
        if debug:
            os.putenv('SCU_WAIT_FOR_DEBUGGER', '1')
        for m, indices in tests_to_run:
            m.run(indices, valgrind)
        if debug:
            for m in tests_to_run:
                m.print_debug_help()
        self.handle_events([m for m, _ in tests_to_run])

    def handle_events(self, modules):
        self.cur_idx = 0
        for m in modules:
            m.reset_status()

        running_modules = modules[:]
        while running_modules:
            # Attempt to read from all running modules
            rs, _, _ = select(running_modules, [], [])
            for r in rs:
                # Handle all pending events
                for event in r.read_events():
                    self.handle_event(r, event)
                # Handle module completion
                if r.finished:
                    running_modules.remove(r)
                    if r.failed:
                        self.handle_event(r, {
                            'event': 'testcase_error',
                            'message': "Test module crashed",
                            'crash': True
                        })
                    # Handle all remaining completed modules
                    while modules[self.cur_idx].finished:
                        self.cur_idx += 1
                        if self.cur_idx == len(modules):
                            break
                        list(map(self.emit, modules[self.cur_idx].events))

    def handle_event(self, module, event):
        if not event:
            return
        # Emit the event if it belongs to the current module
        if module.idx == self.cur_idx:
            self.emit(event)
        # Buffer the event for later if it belongs to any other module
        else:
            module.events.append(event)

    def emit(self, event):
        for observer in self.observers:
            observer.call(event)


class Observer:

    def call(self, event):
        handler = getattr(self, 'handle_' + event['event'], None)
        if handler:
            handler(event)


class TestInfo:

    def __init__(self, name=None, description=None, tags=[], **kwargs):
        self.name = name
        self.description = description
        self.tags = tags
        self.output_file_path = None

    def __repr__(self):
        return self.name


class TestInfoCollector(Observer):

    def __init__(self, modules):
        self.modules = modules
        self.current_idx = -1

    def handle_module_list(self, event):
        self.current_idx += 1

    def handle_testcase_list(self, event):
        module = self.modules[self.current_idx]
        module.tests.append(TestInfo(**event))


class TestEmitter(Observer):

    def __init__(self, modules):
        self.modules = modules
        self.current_module_idx = -1
        self.current_module = None
        self.current_test = None

    def handle_module_start(self, event):
        self.current_module_idx += 1
        self.current_module = self.modules[self.current_module_idx]
        print("  {[name]}".format(event))

    def handle_testcase_start(self, event):
        self.current_test = self.current_module.tests[event['index']]
        self.current_test.output_file_path = event['output']

    def handle_testcase_end(self, event):
        self.print_testcase(event)

    def handle_testcase_error(self, event):
        self.print_testcase(event)

    def print_testcase(self, event):
        event_type = event['event']
        success = event['success'] if event_type == 'testcase_end' else False
        result = (Colors.GREEN + "PASS") if success else (Colors.RED + "FAIL")
        print("    [ {result}{colors.DEFAULT} ] {colors.GRAY}{desc}{colors.DEFAULT}".format(desc=self.current_test.description, result=result, colors=Colors), end='')
        if event_type == 'testcase_end':
            print(" ({event[duration]:.3f} ms)".format(event=event))
            if not success:
                for failure in event['failures']:
                    print("           * " + failure['message'])
                    print("             @ {file}:{line}".format(**failure))
        elif event_type == 'testcase_error':
            print('')
            print("           ! " + event['message'])
        if not success:
            with open(self.current_test.output_file_path) as f:
                for line in f:
                    print("           > " + line, end='')


class SummaryEmitter(Observer):

    def __init__(self):
        self.module_counter = 0
        self.module_fail_counter = 0
        self.test_counter = 0
        self.test_fail_counter = 0
        self.assert_counter = 0
        self.assert_fail_counter = 0
        self.duration_total = 0
        self.cpu_time_total = 0

    def handle_module_start(self, event):
        self.has_reported_failing_test = False

    def handle_testcase_end(self, event):
        self.assert_counter += event['asserts']
        self.assert_fail_counter += len(event['failures'])
        self.test_counter += 1
        self.duration_total += event['duration']
        self.cpu_time_total += event['cpu_time']
        if event['failures']:
            self.test_fail_counter += 1
            self.has_reported_failing_test = True

    def handle_testcase_error(self, event):
        self.test_counter += 1
        self.test_fail_counter += 1
        if event['crash']:
            self.module_counter += 1
            self.module_fail_counter += 1

    def handle_module_end(self, event):
        self.module_counter += 1
        if self.has_reported_failing_test:
            self.module_fail_counter += 1

    def print_summary(self):
        print("\n  Run summary:\n")
        print((
            "  +----------+------------+------------+------------+\n"
            "  |          |       Pass |       Fail |      Total |\n"
            "  +----------+------------+------------+------------+\n"
            "  | Modules  | {:10} | {:10} | {:10} |\n"
            "  | Tests    | {:10} | {:10} | {:10} |\n"
            "  | Asserts  | {:10} | {:10} | {:10} |\n"
            "  | Elapsed  |            |            | {:9.3f}s |\n"
            "  | CPU time |            |            | {:9.3f}s |\n"
            "  +----------+------------+------------+------------+\n"
        ).format(
            self.module_counter - self.module_fail_counter,
            self.module_fail_counter,
            self.module_counter,
            self.test_counter - self.test_fail_counter,
            self.test_fail_counter,
            self.test_counter,
            self.assert_counter - self.assert_fail_counter,
            self.assert_fail_counter,
            self.assert_counter,
            self.duration_total,
            self.cpu_time_total
        ))


class TestCleaner(Observer):

    def __init__(self):
        self.start_event = None

    def handle_testcase_start(self, event):
        self.start_event = event

    def handle_testcase_end(self, event):
        self.clean_testcase()

    def handle_testcase_error(self, event):
        self.clean_testcase()

    def clean_testcase(self):
        os.unlink(self.start_event['output'])


class FilterAction(Action):
    def __call__(self, parser, namespace, values, option_string):
        items = getattr(namespace, self.dest)
        if items is None:
            items = []
        items.append((values, namespace.exclude))
        setattr(namespace, self.dest, items)
        namespace.exclude = False


if __name__ == '__main__':
    # Parse arguments
    parser = ArgumentParser(description="Runs SCU test modules")
    parser.add_argument('module', nargs='+', help="path to test module")
    parser.add_argument('--name', action=FilterAction, default=[], help="filter test cases by name")
    parser.add_argument('--tag', action=FilterAction, default=[], help="filter test cases by tag")
    parser.add_argument('--exclude', action='store_true', help="negates the following filter option")
    parser.add_argument('-g', '--gdb', action='store_true', help="gdb compatibility mode")
    parser.add_argument('-v', '--valgrind', action='store_true', help="valgrind compatibility mode")
    args = parser.parse_args()

    # Create runner
    runner = Runner(args.module)

    # List all tests
    collector = TestInfoCollector(runner.modules)
    runner.register(collector)
    runner.list_modules()
    runner.deregister(collector)

    tests_to_run = []
    for m in runner.modules:
        res = set(range(len(m.tests)))
        for p, exclude in args.name:
            s = set(i for i, t in enumerate(m.tests) if fnmatch(t.name, p))
            if exclude:
                s = set(range(len(m.tests))) - s
            res = res & s
        for p, exclude in args.tag:
            s = set(i for i, t in enumerate(m.tests) if p in t.tags)
            if exclude:
                s = set(range(len(m.tests))) - s
            res = res & s
        if res:
            tests_to_run.append((m, res))

    # Run selected tests
    emitter = SummaryEmitter()
    runner.register(TestEmitter(runner.modules))
    runner.register(emitter)
    runner.register(TestCleaner())
    runner.run_modules(tests_to_run, debug=args.gdb, valgrind=args.valgrind)
    emitter.print_summary()
